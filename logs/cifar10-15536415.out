*** WARNING: This is an experimental installation of pytorch built specifically for MPI / distributed running ***
18: 2018-10-07 22:37:47,398 INFO Initializing
21: 2018-10-07 22:37:47,399 INFO Initializing
24: 2018-10-07 22:37:47,410 INFO Initializing
20: 2018-10-07 22:37:47,407 INFO Initializing
19: 2018-10-07 22:37:47,413 INFO Initializing
17: 2018-10-07 22:37:47,409 INFO Initializing
14: 2018-10-07 22:37:47,413 INFO Initializing
15: 2018-10-07 22:37:47,412 INFO Initializing
22: 2018-10-07 22:37:47,413 INFO Initializing
13: 2018-10-07 22:37:47,415 INFO Initializing
23: 2018-10-07 22:37:47,418 INFO Initializing
11: 2018-10-07 22:37:47,421 INFO Initializing
 4: 2018-10-07 22:37:47,420 INFO Initializing
12: 2018-10-07 22:37:47,427 INFO Initializing
26: 2018-10-07 22:37:47,421 INFO Initializing
25: 2018-10-07 22:37:47,424 INFO Initializing
27: 2018-10-07 22:37:47,424 INFO Initializing
 3: 2018-10-07 22:37:47,428 INFO Initializing
31: 2018-10-07 22:37:47,427 INFO Initializing
28: 2018-10-07 22:37:47,427 INFO Initializing
 2: 2018-10-07 22:37:47,433 INFO Initializing
29: 2018-10-07 22:37:47,434 INFO Initializing
30: 2018-10-07 22:37:47,431 INFO Initializing
 6: 2018-10-07 22:37:47,433 INFO Initializing
 5: 2018-10-07 22:37:47,434 INFO Initializing
 8: 2018-10-07 22:37:47,439 INFO Initializing
 0: 2018-10-07 22:37:47,439 INFO Initializing
 1: 2018-10-07 22:37:47,438 INFO Initializing
 9: 2018-10-07 22:37:47,440 INFO Initializing
 7: 2018-10-07 22:37:47,442 INFO Initializing
16: 2018-10-07 22:37:47,445 INFO Initializing
10: 2018-10-07 22:37:47,459 INFO Initializing
24: 2018-10-07 22:37:47,520 INFO MPI rank 24
 8: 2018-10-07 22:37:47,518 INFO MPI rank 8
20: 2018-10-07 22:37:47,516 INFO MPI rank 20
16: 2018-10-07 22:37:47,515 INFO MPI rank 16
 4: 2018-10-07 22:37:47,517 INFO MPI rank 4
 0: 2018-10-07 22:37:47,517 INFO MPI rank 0
19: 2018-10-07 22:37:47,519 INFO MPI rank 19
 7: 2018-10-07 22:37:47,518 INFO MPI rank 7
22: 2018-10-07 22:37:47,516 INFO MPI rank 22
31: 2018-10-07 22:37:47,518 INFO MPI rank 31
30: 2018-10-07 22:37:47,515 INFO MPI rank 30
23: 2018-10-07 22:37:47,519 INFO MPI rank 23
11: 2018-10-07 22:37:47,519 INFO MPI rank 11
14: 2018-10-07 22:37:47,518 INFO MPI rank 14
15: 2018-10-07 22:37:47,516 INFO MPI rank 15
 3: 2018-10-07 22:37:47,519 INFO MPI rank 3
26: 2018-10-07 22:37:47,514 INFO MPI rank 26
27: 2018-10-07 22:37:47,516 INFO MPI rank 27
28: 2018-10-07 22:37:47,517 INFO MPI rank 28
18: 2018-10-07 22:37:47,516 INFO MPI rank 18
21: 2018-10-07 22:37:47,518 INFO MPI rank 21
25: 2018-10-07 22:37:47,516 INFO MPI rank 25
 9: 2018-10-07 22:37:47,516 INFO MPI rank 9
29: 2018-10-07 22:37:47,518 INFO MPI rank 29
17: 2018-10-07 22:37:47,515 INFO MPI rank 17
 6: 2018-10-07 22:37:47,516 INFO MPI rank 6
12: 2018-10-07 22:37:47,520 INFO MPI rank 12
10: 2018-10-07 22:37:47,517 INFO MPI rank 10
 1: 2018-10-07 22:37:47,517 INFO MPI rank 1
 2: 2018-10-07 22:37:47,518 INFO MPI rank 2
13: 2018-10-07 22:37:47,516 INFO MPI rank 13
 5: 2018-10-07 22:37:47,517 INFO MPI rank 5
 0: 2018-10-07 22:37:47,526 INFO Configuration: {'data_config': {'name': 'cifar10', 'data_path': '$SCRATCH/pytorch-cifar10/data', 'n_train': 32768, 'n_valid': 8192}, 'experiment_config': {'name': 'cifar10', 'output_dir': '$SCRATCH/pytorch-cifar10/output'}, 'model_config': {'model_type': 'resnet50_cifar10', 'optimizer': 'Adam', 'learning_rate': 0.001}, 'train_config': {'batch_size': 64, 'n_epochs': 1}}
19: 2018-10-07 22:37:50,425 INFO Loaded 32768 training samples and 8192 validation samples
27: 2018-10-07 22:37:50,474 INFO Loaded 32768 training samples and 8192 validation samples
14: 2018-10-07 22:37:50,494 INFO Loaded 32768 training samples and 8192 validation samples
21: 2018-10-07 22:37:50,511 INFO Loaded 32768 training samples and 8192 validation samples
 7: 2018-10-07 22:37:50,513 INFO Loaded 32768 training samples and 8192 validation samples
 1: 2018-10-07 22:37:50,515 INFO Loaded 32768 training samples and 8192 validation samples
29: 2018-10-07 22:37:50,520 INFO Loaded 32768 training samples and 8192 validation samples
18: 2018-10-07 22:37:50,521 INFO Loaded 32768 training samples and 8192 validation samples
 5: 2018-10-07 22:37:50,525 INFO Loaded 32768 training samples and 8192 validation samples
22: 2018-10-07 22:37:50,527 INFO Loaded 32768 training samples and 8192 validation samples
23: 2018-10-07 22:37:50,534 INFO Loaded 32768 training samples and 8192 validation samples
17: 2018-10-07 22:37:50,530 INFO Loaded 32768 training samples and 8192 validation samples
10: 2018-10-07 22:37:50,533 INFO Loaded 32768 training samples and 8192 validation samples
 3: 2018-10-07 22:37:50,542 INFO Loaded 32768 training samples and 8192 validation samples
 9: 2018-10-07 22:37:50,541 INFO Loaded 32768 training samples and 8192 validation samples
25: 2018-10-07 22:37:50,551 INFO Loaded 32768 training samples and 8192 validation samples
24: 2018-10-07 22:37:50,557 INFO Loaded 32768 training samples and 8192 validation samples
26: 2018-10-07 22:37:50,555 INFO Loaded 32768 training samples and 8192 validation samples
 2: 2018-10-07 22:37:50,563 INFO Loaded 32768 training samples and 8192 validation samples
11: 2018-10-07 22:37:50,573 INFO Loaded 32768 training samples and 8192 validation samples
15: 2018-10-07 22:37:50,572 INFO Loaded 32768 training samples and 8192 validation samples
16: 2018-10-07 22:37:50,575 INFO Loaded 32768 training samples and 8192 validation samples
 8: 2018-10-07 22:37:50,590 INFO Loaded 32768 training samples and 8192 validation samples
 4: 2018-10-07 22:37:50,592 INFO Loaded 32768 training samples and 8192 validation samples
12: 2018-10-07 22:37:50,595 INFO Loaded 32768 training samples and 8192 validation samples
 0: 2018-10-07 22:37:50,601 INFO Loaded 32768 training samples and 8192 validation samples
31: 2018-10-07 22:37:50,604 INFO Loaded 32768 training samples and 8192 validation samples
20: 2018-10-07 22:37:50,606 INFO Loaded 32768 training samples and 8192 validation samples
13: 2018-10-07 22:37:50,608 INFO Loaded 32768 training samples and 8192 validation samples
30: 2018-10-07 22:37:50,617 INFO Loaded 32768 training samples and 8192 validation samples
 6: 2018-10-07 22:37:50,623 INFO Loaded 32768 training samples and 8192 validation samples
28: 2018-10-07 22:37:50,631 INFO Loaded 32768 training samples and 8192 validation samples
11: 2018-10-07 22:37:50,908 INFO Epoch 0
 9: 2018-10-07 22:37:50,906 INFO Epoch 0
10: 2018-10-07 22:37:50,906 INFO Epoch 0
13: 2018-10-07 22:37:50,906 INFO Epoch 0
 5: 2018-10-07 22:37:50,906 INFO Epoch 0
19: 2018-10-07 22:37:50,909 INFO Epoch 0
27: 2018-10-07 22:37:50,905 INFO Epoch 0
 7: 2018-10-07 22:37:50,907 INFO Epoch 0
18: 2018-10-07 22:37:50,906 INFO Epoch 0
21: 2018-10-07 22:37:50,907 INFO Epoch 0
17: 2018-10-07 22:37:50,905 INFO Epoch 0
14: 2018-10-07 22:37:50,907 INFO Epoch 0
12: 2018-10-07 22:37:50,909 INFO Epoch 0
15: 2018-10-07 22:37:50,906 INFO Epoch 0
 8: 2018-10-07 22:37:50,907 INFO Epoch 0
20: 2018-10-07 22:37:50,906 INFO Epoch 0
 1: 2018-10-07 22:37:50,906 INFO Epoch 0
 2: 2018-10-07 22:37:50,908 INFO Epoch 0
 3: 2018-10-07 22:37:50,908 INFO Epoch 0
 4: 2018-10-07 22:37:50,907 INFO Epoch 0
26: 2018-10-07 22:37:50,904 INFO Epoch 0
28: 2018-10-07 22:37:50,906 INFO Epoch 0
24: 2018-10-07 22:37:50,909 INFO Epoch 0
22: 2018-10-07 22:37:50,906 INFO Epoch 0
31: 2018-10-07 22:37:50,908 INFO Epoch 0
25: 2018-10-07 22:37:50,906 INFO Epoch 0
30: 2018-10-07 22:37:50,904 INFO Epoch 0
23: 2018-10-07 22:37:50,908 INFO Epoch 0
29: 2018-10-07 22:37:50,907 INFO Epoch 0
 6: 2018-10-07 22:37:50,906 INFO Epoch 0
16: 2018-10-07 22:37:50,905 INFO Epoch 0
 0: 2018-10-07 22:37:50,909 INFO Model: 
 0: DistributedDataParallelCPU(
 0:   (module): ResNet(
 0:     (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:     (layer1): Sequential(
 0:       (0): Bottleneck(
 0:         (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential(
 0:           (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         )
 0:       )
 0:       (1): Bottleneck(
 0:         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (2): Bottleneck(
 0:         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:     )
 0:     (layer2): Sequential(
 0:       (0): Bottleneck(
 0:         (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential(
 0:           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
 0:           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         )
 0:       )
 0:       (1): Bottleneck(
 0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (2): Bottleneck(
 0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (3): Bottleneck(
 0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:     )
 0:     (layer3): Sequential(
 0:       (0): Bottleneck(
 0:         (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential(
 0:           (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
 0:           (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         )
 0:       )
 0:       (1): Bottleneck(
 0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (2): Bottleneck(
 0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (3): Bottleneck(
 0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (4): Bottleneck(
 0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (5): Bottleneck(
 0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:     )
 0:     (layer4): Sequential(
 0:       (0): Bottleneck(
 0:         (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential(
 0:           (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
 0:           (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         )
 0:       )
 0:       (1): Bottleneck(
 0:         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:       (2): Bottleneck(
 0:         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
 0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
 0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
 0:         (shortcut): Sequential()
 0:       )
 0:     )
 0:     (linear): Linear(in_features=2048, out_features=10, bias=True)
 0:   )
 0: )
 0: Parameters: 23520842
 0: 2018-10-07 22:37:50,909 INFO Epoch 0
11: 2018-10-07 22:38:43,332 INFO   Training loss: 2.159
19: 2018-10-07 22:38:43,332 INFO   Training loss: 2.159
24: 2018-10-07 22:38:43,333 INFO   Training loss: 2.153
18: 2018-10-07 22:38:43,329 INFO   Training loss: 2.189
31: 2018-10-07 22:38:43,331 INFO   Training loss: 2.194
23: 2018-10-07 22:38:43,332 INFO   Training loss: 2.178
10: 2018-10-07 22:38:43,330 INFO   Training loss: 2.199
27: 2018-10-07 22:38:43,329 INFO   Training loss: 2.223
 7: 2018-10-07 22:38:43,331 INFO   Training loss: 2.178
26: 2018-10-07 22:38:43,328 INFO   Training loss: 2.151
28: 2018-10-07 22:38:43,330 INFO   Training loss: 2.253
17: 2018-10-07 22:38:43,329 INFO   Training loss: 2.251
15: 2018-10-07 22:38:43,330 INFO   Training loss: 2.184
22: 2018-10-07 22:38:43,330 INFO   Training loss: 2.215
29: 2018-10-07 22:38:43,332 INFO   Training loss: 2.118
14: 2018-10-07 22:38:43,332 INFO   Training loss: 2.117
 8: 2018-10-07 22:38:43,332 INFO   Training loss: 2.236
 1: 2018-10-07 22:38:43,331 INFO   Training loss: 2.131
 3: 2018-10-07 22:38:43,333 INFO   Training loss: 2.145
 5: 2018-10-07 22:38:43,331 INFO   Training loss: 2.214
 2: 2018-10-07 22:38:43,333 INFO   Training loss: 2.188
 4: 2018-10-07 22:38:43,332 INFO   Training loss: 2.145
25: 2018-10-07 22:38:43,331 INFO   Training loss: 2.126
30: 2018-10-07 22:38:43,329 INFO   Training loss: 2.165
16: 2018-10-07 22:38:43,330 INFO   Training loss: 2.199
20: 2018-10-07 22:38:43,332 INFO   Training loss: 2.128
21: 2018-10-07 22:38:43,334 INFO   Training loss: 2.259
12: 2018-10-07 22:38:43,336 INFO   Training loss: 2.150
 6: 2018-10-07 22:38:43,333 INFO   Training loss: 2.168
 9: 2018-10-07 22:38:43,333 INFO   Training loss: 2.118
13: 2018-10-07 22:38:43,333 INFO   Training loss: 2.201
 0: 2018-10-07 22:38:43,335 INFO   Training loss: 2.213
 9: 2018-10-07 22:40:07,261 INFO   Validation loss: 2.737 acc: 0.099
 9: 2018-10-07 22:40:07,261 INFO Finished training
 9: 2018-10-07 22:40:07,261 INFO Train samples 1024 time 52.4265s rate 19.5321 samples/s
 9: 2018-10-07 22:40:07,261 INFO Valid rate: 97.6091 samples/s
 9: 2018-10-07 22:40:07,261 INFO All done!
 9: Files already downloaded and verified
 9: Files already downloaded and verified
12: 2018-10-07 22:40:07,471 INFO   Validation loss: 2.746 acc: 0.099
12: 2018-10-07 22:40:07,472 INFO Finished training
12: 2018-10-07 22:40:07,472 INFO Train samples 1024 time 52.4262s rate 19.5322 samples/s
12: 2018-10-07 22:40:07,472 INFO Valid rate: 97.3763 samples/s
12: 2018-10-07 22:40:07,472 INFO All done!
12: Files already downloaded and verified
12: Files already downloaded and verified
 8: 2018-10-07 22:40:07,497 INFO   Validation loss: 2.735 acc: 0.099
 8: 2018-10-07 22:40:07,497 INFO Finished training
 8: 2018-10-07 22:40:07,497 INFO Train samples 1024 time 52.4238s rate 19.5331 samples/s
 8: 2018-10-07 22:40:07,497 INFO Valid rate: 97.3388 samples/s
 8: 2018-10-07 22:40:07,498 INFO All done!
 8: Files already downloaded and verified
 8: Files already downloaded and verified
 5: 2018-10-07 22:40:07,560 INFO   Validation loss: 2.751 acc: 0.099
 5: 2018-10-07 22:40:07,560 INFO Finished training
 5: 2018-10-07 22:40:07,561 INFO Train samples 1024 time 52.4239s rate 19.5331 samples/s
 5: 2018-10-07 22:40:07,561 INFO Valid rate: 97.2595 samples/s
 5: 2018-10-07 22:40:07,561 INFO All done!
 5: Files already downloaded and verified
 5: Files already downloaded and verified
 6: 2018-10-07 22:40:07,736 INFO   Validation loss: 2.740 acc: 0.099
 6: 2018-10-07 22:40:07,736 INFO Finished training
 6: 2018-10-07 22:40:07,736 INFO Train samples 1024 time 52.4263s rate 19.5322 samples/s
 6: 2018-10-07 22:40:07,736 INFO Valid rate: 97.0594 samples/s
 6: 2018-10-07 22:40:07,736 INFO All done!
 6: Files already downloaded and verified
 6: Files already downloaded and verified
26: 2018-10-07 22:40:07,776 INFO   Validation loss: 2.737 acc: 0.099
26: 2018-10-07 22:40:07,776 INFO Finished training
26: 2018-10-07 22:40:07,777 INFO Train samples 1024 time 52.4238s rate 19.5331 samples/s
26: 2018-10-07 22:40:07,777 INFO Valid rate: 97.0202 samples/s
26: 2018-10-07 22:40:07,777 INFO All done!
26: Files already downloaded and verified
26: Files already downloaded and verified
31: 2018-10-07 22:40:07,793 INFO   Validation loss: 2.743 acc: 0.099
31: 2018-10-07 22:40:07,793 INFO Finished training
31: 2018-10-07 22:40:07,794 INFO Train samples 1024 time 52.4231s rate 19.5334 samples/s
31: 2018-10-07 22:40:07,794 INFO Valid rate: 96.9994 samples/s
31: 2018-10-07 22:40:07,794 INFO All done!
31: Files already downloaded and verified
31: Files already downloaded and verified
11: 2018-10-07 22:40:08,082 INFO   Validation loss: 2.754 acc: 0.099
11: 2018-10-07 22:40:08,082 INFO Finished training
11: 2018-10-07 22:40:08,083 INFO Train samples 1024 time 52.4229s rate 19.5334 samples/s
11: 2018-10-07 22:40:08,083 INFO Valid rate: 96.6615 samples/s
11: 2018-10-07 22:40:08,083 INFO All done!
11: Files already downloaded and verified
11: Files already downloaded and verified
 0: 2018-10-07 22:40:08,138 INFO   Validation loss: 2.756 acc: 0.099
10: 2018-10-07 22:40:08,152 INFO   Validation loss: 2.770 acc: 0.099
10: 2018-10-07 22:40:08,152 INFO Finished training
10: 2018-10-07 22:40:08,153 INFO Train samples 1024 time 52.4234s rate 19.5333 samples/s
10: 2018-10-07 22:40:08,153 INFO Valid rate: 96.6158 samples/s
10: 2018-10-07 22:40:08,153 INFO All done!
10: Files already downloaded and verified
10: Files already downloaded and verified
13: 2018-10-07 22:40:08,186 INFO   Validation loss: 2.768 acc: 0.099
13: 2018-10-07 22:40:08,186 INFO Finished training
13: 2018-10-07 22:40:08,186 INFO Train samples 1024 time 52.4268s rate 19.532 samples/s
13: 2018-10-07 22:40:08,186 INFO Valid rate: 96.5453 samples/s
13: 2018-10-07 22:40:08,186 INFO All done!
13: Files already downloaded and verified
13: Files already downloaded and verified
23: 2018-10-07 22:40:08,205 INFO   Validation loss: 2.774 acc: 0.099
23: 2018-10-07 22:40:08,205 INFO Finished training
23: 2018-10-07 22:40:08,206 INFO Train samples 1024 time 52.4233s rate 19.5333 samples/s
23: 2018-10-07 22:40:08,206 INFO Valid rate: 96.55 samples/s
23: 2018-10-07 22:40:08,206 INFO All done!
23: Files already downloaded and verified
23: Files already downloaded and verified
 2: 2018-10-07 22:40:08,243 INFO   Validation loss: 2.767 acc: 0.099
 2: 2018-10-07 22:40:08,243 INFO Finished training
 2: 2018-10-07 22:40:08,243 INFO Train samples 1024 time 52.4242s rate 19.533 samples/s
 2: 2018-10-07 22:40:08,243 INFO Valid rate: 96.4795 samples/s
 2: 2018-10-07 22:40:08,244 INFO All done!
 2: Files already downloaded and verified
 2: Files already downloaded and verified
 7: 2018-10-07 22:40:08,268 INFO   Validation loss: 2.747 acc: 0.099
 7: 2018-10-07 22:40:08,268 INFO Finished training
 7: 2018-10-07 22:40:08,268 INFO Train samples 1024 time 52.4236s rate 19.5332 samples/s
 7: 2018-10-07 22:40:08,268 INFO Valid rate: 96.4499 samples/s
 7: 2018-10-07 22:40:08,268 INFO All done!
 7: Files already downloaded and verified
 7: Files already downloaded and verified
 0: 2018-10-07 22:40:08,307 INFO Saving summaries to /global/cscratch1/sd/sfarrell/pytorch-cifar10/output/summaries.npz
 0: 2018-10-07 22:40:08,320 INFO Finished training
 0: 2018-10-07 22:40:08,320 INFO Train samples 1024 time 52.4254s rate 19.5325 samples/s
 0: 2018-10-07 22:40:08,320 INFO Valid rate: 96.6008 samples/s
 0: 2018-10-07 22:40:08,320 INFO All done!
20: 2018-10-07 22:40:08,328 INFO   Validation loss: 2.765 acc: 0.099
20: 2018-10-07 22:40:08,328 INFO Finished training
20: 2018-10-07 22:40:08,328 INFO Train samples 1024 time 52.4261s rate 19.5323 samples/s
20: 2018-10-07 22:40:08,328 INFO Valid rate: 96.4057 samples/s
20: 2018-10-07 22:40:08,328 INFO All done!
 0: Files already downloaded and verified
 0: Files already downloaded and verified
20: Files already downloaded and verified
20: Files already downloaded and verified
21: 2018-10-07 22:40:08,384 INFO   Validation loss: 2.777 acc: 0.099
21: 2018-10-07 22:40:08,385 INFO Finished training
21: 2018-10-07 22:40:08,385 INFO Train samples 1024 time 52.4262s rate 19.5322 samples/s
21: 2018-10-07 22:40:08,385 INFO Valid rate: 96.3318 samples/s
21: 2018-10-07 22:40:08,385 INFO All done!
21: Files already downloaded and verified
21: Files already downloaded and verified
16: 2018-10-07 22:40:08,708 INFO   Validation loss: 2.751 acc: 0.099
16: 2018-10-07 22:40:08,708 INFO Finished training
16: 2018-10-07 22:40:08,708 INFO Train samples 1024 time 52.4248s rate 19.5328 samples/s
16: 2018-10-07 22:40:08,708 INFO Valid rate: 95.9513 samples/s
16: 2018-10-07 22:40:08,708 INFO All done!
16: Files already downloaded and verified
16: Files already downloaded and verified
15: 2018-10-07 22:40:08,771 INFO   Validation loss: 2.779 acc: 0.099
15: 2018-10-07 22:40:08,771 INFO Finished training
15: 2018-10-07 22:40:08,772 INFO Train samples 1024 time 52.4237s rate 19.5332 samples/s
15: 2018-10-07 22:40:08,772 INFO Valid rate: 95.8915 samples/s
15: 2018-10-07 22:40:08,772 INFO All done!
14: 2018-10-07 22:40:08,773 INFO   Validation loss: 2.750 acc: 0.099
14: 2018-10-07 22:40:08,774 INFO Finished training
14: 2018-10-07 22:40:08,774 INFO Train samples 1024 time 52.4238s rate 19.5331 samples/s
14: 2018-10-07 22:40:08,774 INFO Valid rate: 95.8885 samples/s
14: 2018-10-07 22:40:08,774 INFO All done!
15: Files already downloaded and verified
15: Files already downloaded and verified
14: Files already downloaded and verified
14: Files already downloaded and verified
 4: 2018-10-07 22:40:08,827 INFO   Validation loss: 2.740 acc: 0.099
 4: 2018-10-07 22:40:08,827 INFO Finished training
 4: 2018-10-07 22:40:08,827 INFO Train samples 1024 time 52.4242s rate 19.533 samples/s
 4: 2018-10-07 22:40:08,828 INFO Valid rate: 95.8304 samples/s
 4: 2018-10-07 22:40:08,828 INFO All done!
 4: Files already downloaded and verified
 4: Files already downloaded and verified
19: 2018-10-07 22:40:09,096 INFO   Validation loss: 2.754 acc: 0.099
19: 2018-10-07 22:40:09,096 INFO Finished training
19: 2018-10-07 22:40:09,096 INFO Train samples 1024 time 52.4233s rate 19.5333 samples/s
19: 2018-10-07 22:40:09,096 INFO Valid rate: 95.52 samples/s
19: 2018-10-07 22:40:09,096 INFO All done!
19: Files already downloaded and verified
19: Files already downloaded and verified
27: 2018-10-07 22:40:09,137 INFO   Validation loss: 2.741 acc: 0.099
27: 2018-10-07 22:40:09,138 INFO Finished training
27: 2018-10-07 22:40:09,138 INFO Train samples 1024 time 52.4235s rate 19.5332 samples/s
27: 2018-10-07 22:40:09,138 INFO Valid rate: 95.4702 samples/s
27: 2018-10-07 22:40:09,138 INFO All done!
27: Files already downloaded and verified
27: Files already downloaded and verified
 3: 2018-10-07 22:40:09,158 INFO   Validation loss: 2.757 acc: 0.099
 3: 2018-10-07 22:40:09,158 INFO Finished training
 3: 2018-10-07 22:40:09,158 INFO Train samples 1024 time 52.4239s rate 19.5331 samples/s
 3: 2018-10-07 22:40:09,158 INFO Valid rate: 95.4512 samples/s
 3: 2018-10-07 22:40:09,158 INFO All done!
 3: Files already downloaded and verified
 3: Files already downloaded and verified
24: 2018-10-07 22:40:09,262 INFO   Validation loss: 2.743 acc: 0.099
24: 2018-10-07 22:40:09,263 INFO Finished training
24: 2018-10-07 22:40:09,263 INFO Train samples 1024 time 52.4233s rate 19.5333 samples/s
24: 2018-10-07 22:40:09,263 INFO Valid rate: 95.3429 samples/s
24: 2018-10-07 22:40:09,263 INFO All done!
24: Files already downloaded and verified
24: Files already downloaded and verified
18: 2018-10-07 22:40:09,277 INFO   Validation loss: 2.743 acc: 0.099
18: 2018-10-07 22:40:09,277 INFO Finished training
18: 2018-10-07 22:40:09,277 INFO Train samples 1024 time 52.4232s rate 19.5333 samples/s
18: 2018-10-07 22:40:09,277 INFO Valid rate: 95.3341 samples/s
18: 2018-10-07 22:40:09,277 INFO All done!
18: Files already downloaded and verified
18: Files already downloaded and verified
17: 2018-10-07 22:40:09,344 INFO   Validation loss: 2.757 acc: 0.099
17: 2018-10-07 22:40:09,344 INFO Finished training
17: 2018-10-07 22:40:09,345 INFO Train samples 1024 time 52.4237s rate 19.5332 samples/s
17: 2018-10-07 22:40:09,345 INFO Valid rate: 95.2401 samples/s
17: 2018-10-07 22:40:09,345 INFO All done!
17: Files already downloaded and verified
17: Files already downloaded and verified
29: 2018-10-07 22:40:09,369 INFO   Validation loss: 2.734 acc: 0.099
29: 2018-10-07 22:40:09,370 INFO Finished training
29: 2018-10-07 22:40:09,370 INFO Train samples 1024 time 52.4239s rate 19.5331 samples/s
29: 2018-10-07 22:40:09,370 INFO Valid rate: 95.215 samples/s
29: 2018-10-07 22:40:09,370 INFO All done!
29: Files already downloaded and verified
29: Files already downloaded and verified
22: 2018-10-07 22:40:09,392 INFO   Validation loss: 2.751 acc: 0.099
22: 2018-10-07 22:40:09,393 INFO Finished training
22: 2018-10-07 22:40:09,393 INFO Train samples 1024 time 52.4238s rate 19.5331 samples/s
22: 2018-10-07 22:40:09,393 INFO Valid rate: 95.1878 samples/s
22: 2018-10-07 22:40:09,393 INFO All done!
22: Files already downloaded and verified
22: Files already downloaded and verified
30: 2018-10-07 22:40:09,431 INFO   Validation loss: 2.746 acc: 0.099
30: 2018-10-07 22:40:09,431 INFO Finished training
30: 2018-10-07 22:40:09,431 INFO Train samples 1024 time 52.4242s rate 19.533 samples/s
30: 2018-10-07 22:40:09,432 INFO Valid rate: 95.1495 samples/s
30: 2018-10-07 22:40:09,432 INFO All done!
30: Files already downloaded and verified
30: Files already downloaded and verified
25: 2018-10-07 22:40:09,695 INFO   Validation loss: 2.766 acc: 0.099
25: 2018-10-07 22:40:09,695 INFO Finished training
25: 2018-10-07 22:40:09,695 INFO Train samples 1024 time 52.4242s rate 19.533 samples/s
25: 2018-10-07 22:40:09,695 INFO Valid rate: 94.8775 samples/s
25: 2018-10-07 22:40:09,695 INFO All done!
28: 2018-10-07 22:40:09,698 INFO   Validation loss: 2.728 acc: 0.099
28: 2018-10-07 22:40:09,698 INFO Finished training
28: 2018-10-07 22:40:09,698 INFO Train samples 1024 time 52.4236s rate 19.5332 samples/s
28: 2018-10-07 22:40:09,698 INFO Valid rate: 94.857 samples/s
28: 2018-10-07 22:40:09,698 INFO All done!
25: Files already downloaded and verified
25: Files already downloaded and verified
28: Files already downloaded and verified
28: Files already downloaded and verified
 1: 2018-10-07 22:40:09,843 INFO   Validation loss: 2.768 acc: 0.099
 1: 2018-10-07 22:40:09,844 INFO Finished training
 1: 2018-10-07 22:40:09,844 INFO Train samples 1024 time 52.424s rate 19.5331 samples/s
 1: 2018-10-07 22:40:09,844 INFO Valid rate: 94.6977 samples/s
 1: 2018-10-07 22:40:09,844 INFO All done!
 1: Files already downloaded and verified
 1: Files already downloaded and verified
