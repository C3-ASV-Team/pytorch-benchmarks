*** WARNING: This is an experimental installation of pytorch built specifically for MPI / distributed running ***
6: 2018-10-04 18:03:58,543 INFO Initializing
5: 2018-10-04 18:03:58,546 INFO Initializing
2: 2018-10-04 18:03:58,551 INFO Initializing
1: 2018-10-04 18:03:58,721 INFO Initializing
4: 2018-10-04 18:03:58,867 INFO Initializing
0: 2018-10-04 18:03:58,867 INFO Initializing
3: 2018-10-04 18:03:58,938 INFO Initializing
7: 2018-10-04 18:03:59,120 INFO Initializing
7: 2018-10-04 18:03:59,165 INFO MPI rank 7
1: 2018-10-04 18:03:59,166 INFO MPI rank 1
3: 2018-10-04 18:03:59,168 INFO MPI rank 3
5: 2018-10-04 18:03:59,165 INFO MPI rank 5
6: 2018-10-04 18:03:59,167 INFO MPI rank 6
2: 2018-10-04 18:03:59,163 INFO MPI rank 2
0: 2018-10-04 18:03:59,165 INFO MPI rank 0
4: 2018-10-04 18:03:59,165 INFO MPI rank 4
0: 2018-10-04 18:03:59,169 INFO Configuration: {'data_config': {'name': 'cifar10', 'data_path': '$SCRATCH/pytorch-cifar10/data', 'n_train': 16384, 'n_valid': 10000}, 'experiment_config': {'name': 'cifar10', 'output_dir': '$SCRATCH/pytorch-cifar10/output'}, 'model_config': {'model_type': 'resnet50_cifar10', 'optimizer': 'Adam', 'learning_rate': 0.001}, 'train_config': {'batch_size': 128, 'n_epochs': 1}}
2: 2018-10-04 18:04:01,858 INFO Loaded 16384 training samples and 10000 validation samples
0: 2018-10-04 18:04:01,871 INFO Loaded 16384 training samples and 10000 validation samples
5: 2018-10-04 18:04:01,872 INFO Loaded 16384 training samples and 10000 validation samples
3: 2018-10-04 18:04:01,875 INFO Loaded 16384 training samples and 10000 validation samples
4: 2018-10-04 18:04:01,874 INFO Loaded 16384 training samples and 10000 validation samples
7: 2018-10-04 18:04:01,875 INFO Loaded 16384 training samples and 10000 validation samples
1: 2018-10-04 18:04:01,880 INFO Loaded 16384 training samples and 10000 validation samples
6: 2018-10-04 18:04:01,888 INFO Loaded 16384 training samples and 10000 validation samples
2: 2018-10-04 18:04:02,123 INFO Epoch 0
5: 2018-10-04 18:04:02,125 INFO Epoch 0
7: 2018-10-04 18:04:02,125 INFO Epoch 0
1: 2018-10-04 18:04:02,126 INFO Epoch 0
3: 2018-10-04 18:04:02,128 INFO Epoch 0
6: 2018-10-04 18:04:02,127 INFO Epoch 0
4: 2018-10-04 18:04:02,125 INFO Epoch 0
0: 2018-10-04 18:04:02,127 INFO Model: 
0: DistributedDataParallelCPU(
0:   (module): ResNet(
0:     (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:     (layer1): Sequential(
0:       (0): Bottleneck(
0:         (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential(
0:           (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         )
0:       )
0:       (1): Bottleneck(
0:         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (2): Bottleneck(
0:         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:     )
0:     (layer2): Sequential(
0:       (0): Bottleneck(
0:         (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential(
0:           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
0:           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         )
0:       )
0:       (1): Bottleneck(
0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (2): Bottleneck(
0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (3): Bottleneck(
0:         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:     )
0:     (layer3): Sequential(
0:       (0): Bottleneck(
0:         (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential(
0:           (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
0:           (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         )
0:       )
0:       (1): Bottleneck(
0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (2): Bottleneck(
0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (3): Bottleneck(
0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (4): Bottleneck(
0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (5): Bottleneck(
0:         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:     )
0:     (layer4): Sequential(
0:       (0): Bottleneck(
0:         (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential(
0:           (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
0:           (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         )
0:       )
0:       (1): Bottleneck(
0:         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:       (2): Bottleneck(
0:         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
0:         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
0:         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
0:         (shortcut): Sequential()
0:       )
0:     )
0:     (linear): Linear(in_features=2048, out_features=10, bias=True)
0:   )
0: )
0: Parameters: 23520842
0: 2018-10-04 18:04:02,127 INFO Epoch 0
4: 2018-10-04 18:05:52,075 INFO   Training loss: 2.151
6: 2018-10-04 18:05:52,077 INFO   Training loss: 2.033
5: 2018-10-04 18:05:52,075 INFO   Training loss: 2.094
1: 2018-10-04 18:05:52,076 INFO   Training loss: 2.077
3: 2018-10-04 18:05:52,077 INFO   Training loss: 2.127
2: 2018-10-04 18:05:52,075 INFO   Training loss: 2.155
0: 2018-10-04 18:05:52,078 INFO   Training loss: 2.082
7: 2018-10-04 18:05:52,078 INFO   Training loss: 2.104
3: 2018-10-04 18:07:28,637 INFO   Validation loss: 2.741 acc: 0.100
3: 2018-10-04 18:07:28,895 INFO Finished training
3: 2018-10-04 18:07:28,895 INFO Train samples 2048 time 109.949s rate 18.6268 samples/s
3: 2018-10-04 18:07:28,896 INFO Valid rate: 103.571 samples/s
3: 2018-10-04 18:07:28,896 INFO All done!
3: Files already downloaded and verified
3: Files already downloaded and verified
6: 2018-10-04 18:07:29,514 INFO   Validation loss: 2.735 acc: 0.100
6: 2018-10-04 18:07:29,939 INFO Finished training
6: 2018-10-04 18:07:29,939 INFO Train samples 2048 time 109.949s rate 18.6267 samples/s
6: 2018-10-04 18:07:29,939 INFO Valid rate: 102.631 samples/s
6: 2018-10-04 18:07:29,939 INFO All done!
6: Files already downloaded and verified
6: Files already downloaded and verified
0: 2018-10-04 18:07:30,408 INFO   Validation loss: 2.715 acc: 0.100
0: 2018-10-04 18:07:30,775 INFO Saving summaries to /global/cscratch1/sd/sfarrell/pytorch-cifar10/output/summaries.npz
0: 2018-10-04 18:07:30,788 INFO Finished training
0: 2018-10-04 18:07:30,788 INFO Train samples 2048 time 109.95s rate 18.6266 samples/s
0: 2018-10-04 18:07:30,788 INFO Valid rate: 101.699 samples/s
0: 2018-10-04 18:07:30,788 INFO All done!
0: Files already downloaded and verified
0: Files already downloaded and verified
2: 2018-10-04 18:07:37,756 INFO   Validation loss: 2.732 acc: 0.100
2: 2018-10-04 18:07:38,113 INFO Finished training
2: 2018-10-04 18:07:38,113 INFO Train samples 2048 time 109.952s rate 18.6264 samples/s
2: 2018-10-04 18:07:38,113 INFO Valid rate: 94.6254 samples/s
2: 2018-10-04 18:07:38,113 INFO All done!
2: Files already downloaded and verified
2: Files already downloaded and verified
5: 2018-10-04 18:07:38,188 INFO   Validation loss: 2.737 acc: 0.100
5: 2018-10-04 18:07:38,537 INFO Finished training
5: 2018-10-04 18:07:38,537 INFO Train samples 2048 time 109.949s rate 18.6268 samples/s
5: 2018-10-04 18:07:38,537 INFO Valid rate: 94.2397 samples/s
5: 2018-10-04 18:07:38,537 INFO All done!
5: Files already downloaded and verified
5: Files already downloaded and verified
4: 2018-10-04 18:07:40,906 INFO   Validation loss: 2.738 acc: 0.100
4: 2018-10-04 18:07:41,301 INFO Finished training
4: 2018-10-04 18:07:41,301 INFO Train samples 2048 time 109.949s rate 18.6268 samples/s
4: 2018-10-04 18:07:41,301 INFO Valid rate: 91.8924 samples/s
4: 2018-10-04 18:07:41,301 INFO All done!
4: Files already downloaded and verified
4: Files already downloaded and verified
7: 2018-10-04 18:07:48,206 INFO   Validation loss: 2.737 acc: 0.100
7: 2018-10-04 18:07:48,633 INFO Finished training
7: 2018-10-04 18:07:48,633 INFO Train samples 2048 time 109.952s rate 18.6263 samples/s
7: 2018-10-04 18:07:48,633 INFO Valid rate: 86.1124 samples/s
7: 2018-10-04 18:07:48,633 INFO All done!
7: Files already downloaded and verified
7: Files already downloaded and verified
1: 2018-10-04 18:08:04,039 INFO   Validation loss: 2.701 acc: 0.100
1: 2018-10-04 18:08:04,454 INFO Finished training
1: 2018-10-04 18:08:04,454 INFO Train samples 2048 time 109.949s rate 18.6268 samples/s
1: 2018-10-04 18:08:04,454 INFO Valid rate: 75.7792 samples/s
1: 2018-10-04 18:08:04,454 INFO All done!
1: Files already downloaded and verified
1: Files already downloaded and verified
